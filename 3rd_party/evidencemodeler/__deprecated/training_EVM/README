#########################################################
## Training Weights for use with EVidenceModeler (EVM) ##
#########################################################

Software is provided to find a set of weight values applied to the evidence that is found to optimize performance.  The weights may not be optimal in a global sense, but optimal within the range of weights sampled by the training software.

The training algorithm involves two stages.  First, random sampling is performed across all evidence types.  The weight combination that yields the best performance is chosen, and gradient descent is applied to each evidence type to find the weight settings that further boost performance.  Gradient descent is performed by examining each evidence type in order of descreasing initial weight value, adjusting its weight up and down, and continually adjusting the weight in the direction of increased performance.  This process is applied to each evidence type, in order, and cycled thru them until the performance values stabilize at their maximum value.


Since the more evidence types you have, the greater the challenge to sample sufficient random combinations of weight settings, I find it natural to apply the training algorithm to the genefinding predictions first, find their optimal weight settings, then examine all evidence types including the predictions while holding the relative weights among the prediction programs constant.  An option provided to the training software indicates that the software should proceed along these lines, instead of examing all evidence types simultaneously.


Training EVM requires the following inputs:
1.  a set of trusted gene models to serve as the gold standard and to which accuracy measures are to be based.  This includes all the gene structures in GFF3 format, and a simple list of the gene identifiers (TU feat_names) for the subset to be used for measuring accuracy.
2.  the genome sequence
3.  all evidence types, including gene predictions, est alignments, protein alignments (optionally repeats), provided in GFF3 format.


######################################################
## Generating the Input Data  ########################
######################################################


## 1.  Gene Structures For Training

-Given a list of *model* feat_names (predictions or working models) as file 'model_list.txt', you can retrieve the gene structures from the database in GFF3 format like so:

%  $EGC_SCRIPTS/annotdb_gene_structures_to_GFF3.pl -D $db -G model_list.txt > gold_standard.gff3
 
-we need a list of the gene identfiers (TUs), so will extract these like so:

% cat training_set.gff3 | grep gene | perl -ne 'if (/ID=([^;]+)/) { print "$1\n";}' | sort -u > gold_standard.accs


## 2.  The genome sequence:
-pull it out of the annotation database using a query that retrieves the proper subset of those asmbl_ids under consideration.  For example:

 echo select a.asmbl_id, a.sequence from assembly a, clone_info c where c.asmbl_id = a.asmbl_id and c.is_public = 1 | $EGC_UTILITIES/runsql.dbi -D $db -p ~/.pwdfile | $EGC_SCRIPTS/runsql_to_fasta.dbi > genome.seq



## 3.  All evidence in gff3 format:
-first, get a list of all the asmbl_ids that are going to be used for training purposes:

%   cat training_set.gff3 | $EGC_UTILITIES/print.pl 0 | $EGC_UTILITIES/whitespaceremoval.pl | sort -u > asmbl_list


-retrieve all gene predictions to be considered by EVM.

Run the following command for each prediction type to be examined (ie. genemarkHMM, fgenesh, glimmerHMM, etc):

% $EGC_SCRIPTS/annotdb_gene_structures_to_GFF3.pl -D $db -A asmbl_list -P genemarkHMM > genemarkHMM.gff3

Make sure that each gff3 file is NOT empty (confirming that you spelled the prediction type correctly and predictions exist).  
Combine all your separate prediction gff3 files into a single file:

% cat genemarkHMM.gff3 fgenesh.gff3 glimmerHMM.gff3 > gene_predictions.gff3


-retrieve all genome search results for these assemblies:

% $EGC_SCRIPTS/annot_db_alignments_to_GFF3_format.dbi -D $db -l asmbl_list -X > all_evidence.gff3

-we now need to separate out the transcript from the protein alignments.

First, separate out the transcript alignments:

% cat all_evidence.gff3 | perl -ne '@x = split; if ($x[1] =~ /^(gap2|alignA)/) { print;}' > transcript_alignments.gff3

Next, pull out the protein alignments:

% cat all_evidence.gff3 | perl -ne '@x = split; if ($x[1] =~ /^(nap|genewise)/) { print; } ' > protein_alignments.gff3

If you have other types of evidence that you want to contribute towards the protein coding EVM scores, include them in the regular expression above (ie. TBLASTX).


-if you want to have EVM mask repeats and transposon matches, run the following:

% $EGC_SCRIPTS/get_all_repeats_in_gff3.dbi $db asmbl_list > repeats.gff3

-if you have a PASA database and want to best utilize gene structures inferred from PASA alignments, you should create a terminal exons file (as described in the RUNNING EVM tutorial).  We'll call this file 'pasa_terminal_exons.gff3'.



###################################################################
## Partitioning the Training Inputs, Preparation for Training   ###
###################################################################

Run the following command to prepare the inputs for training.  Each of these files were created or described above.  Again, the repeats file is optional.


% $ANNOT_DEVEL/EvidenceModeler/training_EVM/write_training_files.pl gold_standard.accs gold_standard.gff3 genome.seq gene_predictions.gff3 transcript_alignments.gff3 protein_alignments.gff3 pasa_terminal_exons.gff3 repeats.gff3


##################################################################
## Training EVM ##################################################
##################################################################

Before training EVM, we can calculate the existing gene prediction accuracies measured against our gold standard gene set.  Do this like so:

% $ANNOT_DEVEL/EvidenceModeler/training_EVM/train_weights.pl --genome genome.seq -L "genemarkHMM,fgenesh,glimmerHMM" -g gene_predictions.gff3 --just_measure_other_prediction_accuracies


To train the weights, run the following:

% $ANNOT_DEVEL/EvidenceModeler/training_EVM/train_weights.pl --genome genome.seq -L "genemarkHMM,fgenesh,glimmerHMM" -g gene_predictions.gff3 -e transcript_alignments.gff3 -p protein_alignments.gff3 -t pasa_terminal_exons.gff3 -r repeats.gff3 --use_fixed_genefinder_weights | & tee training.log

Under these settings, the training software will evaluate the genefinders first, followed by all the evidence including the genefinders with their optimal relative contributions fixed.  The random sampling involves 100 iterations of random weight combinations, followed by gradient descent.  The number of random interations can be changed using the --num_rand_iterations parameter.

If your data includes pasa or genewise, consider using the additional options --stitch_ends and --extend_to_terminal as described in the RUNNING EVM tutorial.  These parameters and values are provided to this training software identically.

When the training software has finished running, it will report the optimal set of weights and write these to a file called 'final_optimized_weights.$pid.txt'. 

#################################################
## Experimenting with custom weight settings: ###
#################################################

You can compute accuracies for any set of weights by creating a weights file (ie. 'my_weights.txt') (such as by copying the final_optimized_weights.$pid.txt file and editing the weight values) and supplying this to the training software like so:

%  $ANNOT_DEVEL/EvidenceModeler/training_EVM/train_weights.pl --genome genome.seq -L "genemarkHMM,fgenesh,glimmerHMM" -g gene_predictions.gff3 -e transcript_alignments.gff3 -p protein_alignments.gff3 -t pasa_terminal_exons.gff3 -r repeats.gff3 --init_weights_file my_weights.txt --just_score_existing_weights














